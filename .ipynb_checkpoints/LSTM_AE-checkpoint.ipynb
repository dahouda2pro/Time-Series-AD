{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing some Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from influxdb import InfluxDBClient\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetching Data: EP_Propulsion1.Thing_HMD8310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to InfluxDB and fetch data\n",
    "client = InfluxDBClient(host='localhost', port=8086)\n",
    "client.switch_database('ISS')\n",
    "\n",
    "# Query to the Database for one measurement\n",
    "\n",
    "query1 = 'SELECT * FROM \"EP_Propulsion1.Thing_HMD8310\"'\n",
    "results1 = client.query(query1)\n",
    "EP_Propulsion1_Thing_HMD8310 = pd.DataFrame.from_records(results1.get_points())\n",
    "\n",
    "print(EP_Propulsion1_Thing_HMD8310.shape)\n",
    "EP_Propulsion1_Thing_HMD8310.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_Propulsion1_Thing_HMD8310.to_csv(\"Data/EP_Propulsion1_Thing_HMD8310.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ISO 8601 time to datetime\n",
    "def ISO_8601_To_Datetime(s):\n",
    "    return datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The data\n",
    "df = pd.read_csv('Data/EP_Propulsion1_Thing_HMD8310.csv', parse_dates=[1], index_col=0, date_parser=ISO_8601_To_Datetime)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 2 features : Time and MotorRPM for Univariate Time Serie Analysis\n",
    "df = df.loc[:, ['time','MotorRPM','MotorPower']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"MotorRPM\"], mode='lines', name='Motor RPM'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"MotorPower\"], mode='lines', name='Motor Power', yaxis='y2'))\n",
    "\n",
    "fig.update_layout(title_text=\"Motor Power vs Motor RPM\",\n",
    "                  yaxis1=dict(title=\"Motor RPM in rpm/min\", side='left'),\n",
    "                  yaxis2=dict(title=\"Motor Power\", side='right', anchor=\"x\", overlaying=\"y\")\n",
    "                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph observations\n",
    "We can see that in August 31st and September 15th, and September 20th there are some misproduction areas that could be considered anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[:2000,:]\n",
    "df = df[['time','MotorRPM','MotorPower']]\n",
    "df_timestamp = df[['time']]\n",
    "df_ = df[['MotorRPM','MotorPower']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prp = .6\n",
    "train = df_.loc[:df_.shape[0] * train_prp]\n",
    "test = df_.loc[df_.shape[0] * train_prp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize The Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.transform(test)\n",
    "\n",
    "print(\"X train Shape:\", X_train.shape)\n",
    "print(\"X test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the Dimension of the Train and Test set for LSTM Model\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "print(\"X train Shape:\", X_train.shape)\n",
    "print(\"X test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_model(X):\n",
    "    # The Encoder\n",
    "    inputs = Input(shape=(X.shape[1],  X.shape[2]))\n",
    "    L1 = LSTM(16, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n",
    "    \n",
    "    L3 = RepeatVector(X.shape[1])(L2)\n",
    "    \n",
    "    # The Decoder\n",
    "    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n",
    "    output = TimeDistributed(Dense(X.shape[2]))(L5)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder_model(X_train)\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch = 25\n",
    "history = model.fit(X_train, X_train, epochs=epochs, batch_size=batch, validation_split=.2, verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(len(history['loss']))], y=history['loss'], mode='lines', name='loss'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(len(history['val_loss']))], y=history['val_loss'], mode='lines', name='validation loss'))\n",
    "\n",
    "fig.update_layout(title=\"Autoencoder error loss over epochs\", yaxis=dict(title=\"Loss\"), xaxis=dict(title=\"Epoch\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = scaler.inverse_transform(X_pred)\n",
    "X_pred = pd.DataFrame(X_pred, columns=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame()\n",
    "scores['Motor_train'] = train['MotorRPM']\n",
    "scores[\"Motor_predicted\"] = X_pred[\"MotorRPM\"]\n",
    "scores['loss_mae'] = (scores['Motor_train']-scores['Motor_predicted']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=scores['loss_mae'])])\n",
    "fig.update_layout(title=\"Error distribution\", \n",
    "                 xaxis=dict(title=\"Error delta between predicted and real data [Motor RPM]\"),\n",
    "                 yaxis=dict(title=\"Data point counts\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_test)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = scaler.inverse_transform(X_pred)\n",
    "X_pred = pd.DataFrame(X_pred, columns=train.columns)\n",
    "X_pred.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X_pred\n",
    "scores['datetime'] = df_timestamp.loc[1893:]\n",
    "scores['real MotorRPM'] = test['MotorRPM']\n",
    "scores[\"loss_mae\"] = (scores['real MotorRPM'] - scores['MotorRPM']).abs()\n",
    "scores['Threshold'] = 8\n",
    "scores['Anomaly'] = np.where(scores[\"loss_mae\"] > scores[\"Threshold\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scores['datetime'], \n",
    "                         y=scores['loss_mae'], \n",
    "                         name=\"Loss\"))\n",
    "fig.add_trace(go.Scatter(x=scores['datetime'], \n",
    "                         y=scores['Threshold'],\n",
    "                         name=\"Threshold\"))\n",
    "\n",
    "fig.update_layout(title=\"Error Timeseries and Threshold\", \n",
    "                 xaxis=dict(title=\"DateTime\"),\n",
    "                 yaxis=dict(title=\"Loss\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = scores[scores['Anomaly'] == 1][['real MotorRPM']]\n",
    "anomalies = anomalies.rename(columns={'real MotorRPM':'anomalies'})\n",
    "scores = scores.merge(anomalies, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"real MotorRPM\"], mode='lines', name='Motor RPM'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\"Anomalies Detected LSTM Autoencoder\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9309e66488dead2b3ef50f8102e1dacf5788aeb67c8de09ce5afbc9fc543d825"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
