{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing some Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from influxdb import InfluxDBClient\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetching Data: DE1Thing_HMD8310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to InfluxDB and fetch data\n",
    "client = InfluxDBClient(host='localhost', port=8086)\n",
    "client.switch_database('ISS')\n",
    "\n",
    "# Query to the Database for one measurement\n",
    "\n",
    "#query1 = 'SELECT * FROM \"DE1Thing_HMD8310\"'\n",
    "query1 = 'SELECT * FROM \"DE1Thing_HMD8310\" WHERE time >= \\'2022-08-29T23:28:00Z\\' AND time < \\'2023-01-26T08:00:00Z\\''\n",
    "results1 = client.query(query1)\n",
    "DE1Thing_HMD8310 = pd.DataFrame.from_records(results1.get_points())\n",
    "\n",
    "print(DE1Thing_HMD8310.shape)\n",
    "DE1Thing_HMD8310.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE1Thing_HMD8310.to_csv(\"Data/DE1Thing_HMD8310.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ISO 8601 time to datetime\n",
    "def ISO_8601_To_Datetime(s):\n",
    "    return datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The data\n",
    "df = pd.read_csv('Data/DE1Thing_HMD8310.csv', parse_dates=[1], index_col=0, date_parser=ISO_8601_To_Datetime)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 5 features\n",
    "df = df.loc[:, ['time','CFWInletPress','CFWInletTemp', 'CFWOutletTempA', 'CFWOutletTempB']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for blank values and Data Types.\n",
    "def overview(df: pd.DataFrame, timestamp_col: str= None) -> None:\n",
    "    print('Null Count:\\n', df.isnull().sum(), '\\n')\n",
    "    print('Data Types:\\n:', df.dtypes)\n",
    "    \n",
    "    if timestamp_col is not None:\n",
    "        print('\\nDate Range: \\n\\nStart:\\t', df[timestamp_col].min())\n",
    "        print('End:\\t', df[timestamp_col].max())\n",
    "        print('Days:\\t',(df[timestamp_col].max() - df[timestamp_col].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(df, timestamp_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWInletPress\"], mode='lines', name='CFWInletPress'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWInletTemp\"], mode='lines', name='CFWInletTemp', yaxis='y2'))\n",
    "\n",
    "fig.update_layout(title_text=\"CFWInletPress vs CFWInletTemp\",\n",
    "                  yaxis1=dict(title=\"CFWInletPress\", side='left'),\n",
    "                  yaxis2=dict(title=\"CFWInletTemp\", side='right', anchor=\"x\", overlaying=\"y\")\n",
    "                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWInletPress\"], mode='lines', name='CFWInletPress'))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWOutletTempA\"], mode='lines', name='CFWOutletTempA', yaxis='y2'))\n",
    "\n",
    "fig.update_layout(title_text=\"CFWInletPress vs CFWOutletTempB\",\n",
    "                  yaxis1=dict(title=\"CFWInletPress\", side='left'),\n",
    "                  yaxis2=dict(title=\"CFWOutletTempB\", side='right', anchor=\"x\", overlaying=\"y\")\n",
    "                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWOutletTempA\"], mode='lines', name='CFWOutletTempA'))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df[\"time\"], y=df[\"CFWOutletTempB\"], mode='lines', name='CFWOutletTempB', yaxis='y2'))\n",
    "\n",
    "fig.update_layout(title_text=\"CFWOutletTempA vs CFWOutletTempB\",\n",
    "                  yaxis1=dict(title=\"CFWOutletTempA\", side='left'),\n",
    "                  yaxis2=dict(title=\"CFWOutletTempB\", side='right', anchor=\"x\", overlaying=\"y\")\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[:2000,:]\n",
    "df = df.loc[:, ['time','CFWInletPress','CFWInletTemp', 'CFWOutletTempA', 'CFWOutletTempB']]\n",
    "df_timestamp = df[['time']]\n",
    "df_ = df[['CFWInletPress','CFWInletTemp', 'CFWOutletTempA', 'CFWOutletTempB']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prp = .6\n",
    "train = df_.loc[:df_.shape[0] * train_prp]\n",
    "test = df_.loc[df_.shape[0] * train_prp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize The Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.transform(test)\n",
    "\n",
    "print(\"X train Shape:\", X_train.shape)\n",
    "print(\"X test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the Dimension of the Train and Test set for LSTM Model\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "print(\"X train Shape:\", X_train.shape)\n",
    "print(\"X test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_model(X):\n",
    "    # The Encoder\n",
    "    inputs = Input(shape=(X.shape[1],  X.shape[2]))\n",
    "    L1 = LSTM(16, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n",
    "    \n",
    "    L3 = RepeatVector(X.shape[1])(L2)\n",
    "    \n",
    "    # The Decoder\n",
    "    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n",
    "    output = TimeDistributed(Dense(X.shape[2]))(L5)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder_model(X_train)\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch = 25\n",
    "history = model.fit(X_train, X_train, epochs=epochs, batch_size=batch, validation_split=.2, verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(len(history['loss']))], y=history['loss'], mode='lines', name='loss'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[x for x in range(len(history['val_loss']))], y=history['val_loss'], mode='lines', name='validation loss'))\n",
    "\n",
    "fig.update_layout(title=\"Autoencoder error loss over epochs\", yaxis=dict(title=\"Loss\"), xaxis=dict(title=\"Epoch\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how loss & mse went down\n",
    "epoch_loss = history['loss']\n",
    "epoch_val_loss = history['val_loss']\n",
    "epoch_mae = history['accuracy']\n",
    "epoch_val_mae = history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\n",
    "plt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Test Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#lt.title('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Figure_Loss.jpeg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how loss & mse went down\n",
    "epoch_loss = history['loss']\n",
    "epoch_val_loss = history['val_loss']\n",
    "epoch_mae = history['accuracy']\n",
    "epoch_val_mae = history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train Acc')\n",
    "plt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Test Acc')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.savefig('Figure_Acc.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = scaler.inverse_transform(X_pred)\n",
    "X_pred = pd.DataFrame(X_pred, columns=train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Anomaly Detection for CFWInletPress with LSTM-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFWInletPress, CFWInletTemp, CFWOutletTempA, CFWOutletTempB\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores['CFWInletPress_train'] = train['CFWInletPress']\n",
    "scores[\"CFWInletPress_predicted\"] = X_pred[\"CFWInletPress\"]\n",
    "scores['loss_mae'] = (scores['CFWInletPress_train']-scores['CFWInletPress_predicted']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=scores['loss_mae'])])\n",
    "fig.update_layout(title=\"Error distribution\", \n",
    "                 xaxis=dict(title=\"Error delta between predicted and real data [CFWInletPress]\"),\n",
    "                 yaxis=dict(title=\"Data point counts\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_test)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = scaler.inverse_transform(X_pred)\n",
    "X_pred = pd.DataFrame(X_pred, columns=train.columns)\n",
    "X_pred.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X_pred\n",
    "scores['datetime'] = df_timestamp.loc[1893:]\n",
    "scores['real CFWInletPress'] = test['CFWInletPress']\n",
    "scores[\"loss_mae\"] = (scores['real CFWInletPress'] - scores['CFWInletPress']).abs()\n",
    "scores['Threshold'] = 3\n",
    "scores['Anomaly'] = np.where(scores[\"loss_mae\"] > scores[\"Threshold\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scores['datetime'], \n",
    "                         y=scores['loss_mae'], \n",
    "                         name=\"Loss\"))\n",
    "fig.add_trace(go.Scatter(x=scores['datetime'], \n",
    "                         y=scores['Threshold'],\n",
    "                         name=\"Threshold\"))\n",
    "\n",
    "fig.update_layout(title=\"Error Timeseries and Threshold\", \n",
    "                 xaxis=dict(title=\"DateTime\"),\n",
    "                 yaxis=dict(title=\"Loss\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = scores[scores['Anomaly'] == 1][['real CFWInletPress']]\n",
    "anomalies = anomalies.rename(columns={'real CFWInletPress':'anomalies'})\n",
    "scores = scores.merge(anomalies, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"real CFWInletPress\"], mode='lines', name='CFWInletPress'))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Test Data\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"real CFWInletPress\"], mode='lines', name='CFWInletPress'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\"Anomalies Detected for CFWInletPress with LSTM-AE\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Anomaly Detection for CFWInletTemp with LSTM-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFWInletPress, CFWInletTemp, CFWOutletTempA, CFWOutletTempB\n",
    "\n",
    "scores_2 = pd.DataFrame()\n",
    "scores_2['CFWInletTemp_train'] = train['CFWInletTemp']\n",
    "scores_2[\"CFWInletTemp_predicted\"] = X_pred[\"CFWInletTemp\"]\n",
    "scores_2['loss_mae'] = (scores_2['CFWInletTemp_train'] - scores_2['CFWInletTemp_predicted']).abs()\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=scores_2['loss_mae'])])\n",
    "fig.update_layout(title=\"Error distribution\", \n",
    "                 xaxis=dict(title=\"Error delta between predicted and real data [CFWInletTemp]\"),\n",
    "                 yaxis=dict(title=\"Data point counts\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = X_pred\n",
    "scores_2['datetime'] = df_timestamp.loc[1893:]\n",
    "scores_2['real CFWInletTemp'] = test['CFWInletTemp']\n",
    "scores_2[\"loss_mae\"] = (scores_2['real CFWInletTemp'] - scores_2['CFWInletTemp']).abs()\n",
    "scores_2['Threshold'] = 3\n",
    "scores_2['Anomaly'] = np.where(scores_2[\"loss_mae\"] > scores_2[\"Threshold\"], 1, 0)\n",
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scores_2['datetime'], y=scores_2['loss_mae'], name=\"Loss\"))\n",
    "fig.add_trace(go.Scatter(x=scores_2['datetime'], y=scores_2['Threshold'], name=\"Threshold\"))\n",
    "\n",
    "fig.update_layout(title=\"CFWInletTemp: Error Timeseries and Threshold\", xaxis=dict(title=\"DateTime\"), yaxis=dict(title=\"Loss\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_2 = scores_2[scores_2['Anomaly'] == 1][['real CFWInletTemp']]\n",
    "anomalies_2 = anomalies_2.rename(columns={'real CFWInletTemp':'anomalies'})\n",
    "scores_2 = scores_2.merge(anomalies_2, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"real CFWInletTemp\"], mode='lines', name='CFWInletTemp'))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\" Test Data : CFWInletTemp\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"real CFWInletTemp\"], mode='lines', name='CFWInletTemp'))\n",
    "fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"anomalies\"], name='CFWInletTemp Anomalies', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "fig.update_layout(title_text=\"Anomalies Detected in CFWInletTemp with LSTM-AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"anomalies\"], name='CFWInletTemp Anomalies', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"anomalies\"], name='CFWInletPress Anomalies', mode='markers', marker=dict(color=\"black\", size=11, line=dict(color=\"black\", width=2))))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"real CFWInletTemp\"], mode='lines', name='CFWInletTemp'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"real CFWInletPress\"], mode='lines', name='CFWInletPress'))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Anomalies Detected in CFWInletTemp with LSTM-AE\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Anomaly Detection for CFWOutletTempA with LSTM-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CFWOutletTempA\n",
    "\n",
    "scores_3 = pd.DataFrame()\n",
    "scores_3['CFWOutletTempA_train'] = train['CFWOutletTempA']\n",
    "scores_3[\"CFWOutletTempA_predicted\"] = X_pred[\"CFWOutletTempA\"]\n",
    "scores_3['loss_mae'] = (scores_3['CFWOutletTempA_train'] - scores_3['CFWOutletTempA_predicted']).abs()\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=scores_3['loss_mae'])])\n",
    "fig.update_layout(title=\"Error distribution\", \n",
    "                 xaxis=dict(title=\"Error delta between predicted and real data [CFWOutletTempA]\"),\n",
    "                 yaxis=dict(title=\"Data point counts\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_3 = X_pred\n",
    "scores_3['datetime'] = df_timestamp.loc[1893:]\n",
    "scores_3['real CFWOutletTempA'] = test['CFWOutletTempA']\n",
    "scores_3[\"loss_mae\"] = (scores_3['real CFWOutletTempA'] - scores_3['CFWOutletTempA']).abs()\n",
    "scores_3['Threshold'] = 3\n",
    "scores_3['Anomaly'] = np.where(scores_3[\"loss_mae\"] > scores_3[\"Threshold\"], 1, 0)\n",
    "scores_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scores_3['datetime'], y=scores_3['loss_mae'], name=\"Loss\"))\n",
    "fig.add_trace(go.Scatter(x=scores_3['datetime'], y=scores_3['Threshold'], name=\"Threshold\"))\n",
    "\n",
    "fig.update_layout(title=\"CFWOutletTempA: Error Timeseries and Threshold\", xaxis=dict(title=\"DateTime\"), yaxis=dict(title=\"Loss\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_3['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_3 = scores_3[scores_3['Anomaly'] == 1][['real CFWOutletTempA']]\n",
    "anomalies_3 = anomalies_3.rename(columns={'real CFWOutletTempA':'anomalies'})\n",
    "scores_3 = scores_3.merge(anomalies_3, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_3[\"datetime\"], y=scores_3[\"real CFWOutletTempA\"], mode='lines', name='CFWOutletTempA'))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\" Test Data : CFWOutletTempA\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_3[\"datetime\"], y=scores_3[\"real CFWOutletTempA\"], mode='lines', name='CFWOutletTempA'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_3[\"datetime\"], y=scores_3[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\" Anomalies Detected in CFWOutletTempA with LSTM_AE\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Anomaly Detection for CFWOutletTempB with LSTM-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CFWOutletTempB\n",
    "\n",
    "scores_4 = pd.DataFrame()\n",
    "scores_4['CFWOutletTempB_train'] = train['CFWOutletTempB']\n",
    "scores_4[\"CFWOutletTempB_predicted\"] = X_pred[\"CFWOutletTempB\"]\n",
    "scores_4['loss_mae'] = (scores_4['CFWOutletTempB_train'] - scores_4['CFWOutletTempB_predicted']).abs()\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=scores_4['loss_mae'])])\n",
    "fig.update_layout(title=\"Error distribution\", \n",
    "                 xaxis=dict(title=\"Error delta between predicted and real data [CFWOutletTempB]\"),\n",
    "                 yaxis=dict(title=\"Data point counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_4 = X_pred\n",
    "scores_4['datetime'] = df_timestamp.loc[1893:]\n",
    "scores_4['real CFWOutletTempB'] = test['CFWOutletTempB']\n",
    "scores_4[\"loss_mae\"] = (scores_4['real CFWOutletTempB'] - scores_4['CFWOutletTempB']).abs()\n",
    "scores_4['Threshold'] = 3\n",
    "scores_4['Anomaly'] = np.where(scores_4[\"loss_mae\"] > scores_4[\"Threshold\"], 1, 0)\n",
    "scores_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scores_4['datetime'], y=scores_4['loss_mae'], name=\"Loss\"))\n",
    "fig.add_trace(go.Scatter(x=scores_4['datetime'], y=scores_4['Threshold'], name=\"Threshold\"))\n",
    "\n",
    "fig.update_layout(title=\"CFWOutletTempB: Error Timeseries and Threshold\", xaxis=dict(title=\"DateTime\"), yaxis=dict(title=\"Loss\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_4['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_4 = scores_4[scores_4['Anomaly'] == 1][['real CFWOutletTempB']]\n",
    "anomalies_4 = anomalies_4.rename(columns={'real CFWOutletTempB':'anomalies'})\n",
    "scores_4 = scores_4.merge(anomalies_4, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_4[\"datetime\"], y=scores_4[\"real CFWOutletTempB\"], mode='lines', name='CFWOutletTempB'))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=scores_2[\"datetime\"], y=scores_2[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\" Test Data : CFWOutletTempB\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_4[\"datetime\"], y=scores_4[\"real CFWOutletTempB\"], mode='lines', name='CFWOutletTempB'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_4[\"datetime\"], y=scores_4[\"anomalies\"], name='Anomaly', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "fig.update_layout(title_text=\" Anomalies Detected in CFWOutletTempB\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_3[\"datetime\"], y=scores_3[\"real CFWOutletTempA\"], mode='lines', name='CFWOutletTempA'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_3[\"datetime\"], y=scores_3[\"anomalies\"], name='CFWOutletTempB Anomalies', mode='markers', marker=dict(color=\"blue\", size=11, line=dict(color=\"blue\", width=2))))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_4[\"datetime\"], y=scores_4[\"real CFWOutletTempB\"], mode='lines', name='CFWOutletTempB'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=scores_4[\"datetime\"], y=scores_4[\"anomalies\"], name='CFWOutletTempB Anomalies', mode='markers', marker=dict(color=\"red\", size=11, line=dict(color=\"red\", width=2))))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\" Anomalies Detected in CFWOutletTempA and CFWOutletTempB\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9309e66488dead2b3ef50f8102e1dacf5788aeb67c8de09ce5afbc9fc543d825"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
